{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Sentence-BERT](https://arxiv.org/pdf/1908.10084.pdf)\n",
    "\n",
    "[Reference Code](https://www.pinecone.io/learn/series/nlp/train-sentence-transformers-softmax/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import re\n",
    "from   random import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "torch.set_default_device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sung2_8l7o06c\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'premise': Value(dtype='string', id=None),\n",
       "  'hypothesis': Value(dtype='string', id=None),\n",
       "  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None),\n",
       "  'idx': Value(dtype='int32', id=None)},\n",
       " {'premise': Value(dtype='string', id=None),\n",
       "  'hypothesis': Value(dtype='string', id=None),\n",
       "  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None)})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "snli = datasets.load_dataset('snli')\n",
    "mnli = datasets.load_dataset('glue', 'mnli')\n",
    "mnli['train'].features, snli['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of datasets to remove 'idx' column from\n",
    "mnli.column_names.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'idx' column from each dataset\n",
    "for column_names in mnli.column_names.keys():\n",
    "    mnli[column_names] = mnli[column_names].remove_columns('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli.column_names.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([-1,  0,  1,  2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])\n",
    "#snli also have -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are -1 values in the label feature, these are where no class could be decided so we remove\n",
    "snli = snli.filter(\n",
    "    lambda x: 0 if x['label'] == -1 else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([0, 1, 2]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])\n",
    "#snli also have -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have your two DatasetDict objects named snli and mnli\n",
    "from datasets import DatasetDict\n",
    "# Merge the two DatasetDict objects\n",
    "raw_dataset = DatasetDict({\n",
    "    'train': datasets.concatenate_datasets([snli['train'], mnli['train']]).shuffle(seed=55).select(list(range(1000))),\n",
    "    'test': datasets.concatenate_datasets([snli['test'], mnli['test_mismatched']]).shuffle(seed=55).select(list(range(100))),\n",
    "    'validation': datasets.concatenate_datasets([snli['validation'], mnli['validation_mismatched']]).shuffle(seed=55).select(list(range(1000)))\n",
    "})\n",
    "#remove .select(list(range(1000))) in order to use full dataset\n",
    "# Now, merged_dataset_dict contains the combined datasets from snli and mnli\n",
    "raw_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_function(examples):\n",
    "#     max_seq_length = 512\n",
    "#     padding = 'max_length'\n",
    "#     # Tokenize the premise\n",
    "#     premise_result = tokenizer(\n",
    "#         examples['premise'], padding=padding, max_length=max_seq_length, truncation=True)\n",
    "#     #num_rows, max_seq_length\n",
    "#     # Tokenize the hypothesis\n",
    "#     hypothesis_result = tokenizer(\n",
    "#         examples['hypothesis'], padding=padding, max_length=max_seq_length, truncation=True)\n",
    "#     #num_rows, max_seq_length\n",
    "#     # Extract labels\n",
    "#     labels = examples[\"label\"]\n",
    "#     #num_rows\n",
    "#     return {\n",
    "#         \"premise_input_ids\": premise_result[\"input_ids\"],\n",
    "#         \"premise_attention_mask\": premise_result[\"attention_mask\"],\n",
    "#         \"hypothesis_input_ids\": hypothesis_result[\"input_ids\"],\n",
    "#         \"hypothesis_attention_mask\": hypothesis_result[\"attention_mask\"],\n",
    "#         \"labels\" : labels\n",
    "#     }\n",
    "\n",
    "# tokenized_datasets = raw_dataset.map(\n",
    "#     preprocess_function,\n",
    "#     batched=True,\n",
    "# )\n",
    "\n",
    "# tokenized_datasets = tokenized_datasets.remove_columns(['premise','hypothesis','label'])\n",
    "# tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "\n",
    "tokenizer = spacy.load(\"en_core_web_sm\")\n",
    "word2id = pickle.load(open('./model/elements/word2id.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    max_seq_length = 512\n",
    "    # Tokenize the premise\n",
    "\n",
    "    # tokenized_premise = []\n",
    "    # for sent in examples['premise']:\n",
    "    #     print(sent)\n",
    "    #     tokenized_premise.append(tokenizer(re.sub(\"[.,!?\\\\-]=\", '', sent.lower())))\n",
    "\n",
    "    tokenized_premise = [tokenizer(re.sub(\"[.,!?\\\\-']=\", ' ', sent.lower())) for sent in examples['premise']]\n",
    "\n",
    "    # premise_input_ids = []\n",
    "    # for tokens in tokenized_premise:\n",
    "    #     premise_input_ids.append([])\n",
    "    #     premise_input_ids[-1].append([word2id['[CLS]']])\n",
    "    #     for token in tokens:\n",
    "    #         try:\n",
    "    #             premise_input_ids[-1].append(word2id[token])\n",
    "    #         except KeyError as k:\n",
    "    #             pass\n",
    "    #     premise_input_ids[-1].append([word2id['[SEP]']])\n",
    "    \n",
    "    premise_input_ids = [[word2id['[CLS]']] + [word2id[str(token)] for token in tokens if str(token) in word2id] + [word2id['[SEP]']] for tokens in tokenized_premise]\n",
    "    premise_pad_len = [max_seq_length - len(premise) for premise in premise_input_ids]\n",
    "    premise_attn_mask = [([1] * len(premise)) + ([0] * pad_len) for premise, pad_len in zip(premise_input_ids, premise_pad_len)]\n",
    "    premise_input_ids = [premise + [word2id['[PAD]']] * pad_len for premise, pad_len in zip(premise_input_ids, premise_pad_len)]\n",
    "\n",
    "    #num_rows, max_seq_length\n",
    "    # Tokenize the hypothesis\n",
    "    tokenized_hypothesis = [tokenizer(re.sub(\"[.,!?\\\\-]=\", '', sent.lower())) for sent in examples['hypothesis']]\n",
    "\n",
    "    # hypothesis_input_ids = []\n",
    "    # for tokens in tokenized_hypothesis:\n",
    "    #     premise_input_ids.append([])\n",
    "    #     hypothesis_input_ids[-1].append([word2id['[CLS]']])\n",
    "    #     for token in tokens:\n",
    "    #         try:\n",
    "    #             hypothesis_input_ids[-1].append(word2id[token])\n",
    "    #         except KeyError as k:\n",
    "    #             pass\n",
    "    #     hypothesis_input_ids[-1].append([word2id['[SEP]']])\n",
    "\n",
    "    hypothesis_input_ids = [[word2id['[CLS]']] + [word2id[str(token)] for token in tokens if str(token) in word2id] + [word2id['[SEP]']] for tokens in tokenized_hypothesis]\n",
    "    hypothesis_pad_len = [max_seq_length - len(hypothesis) for hypothesis in hypothesis_input_ids]\n",
    "    hypothesis_attn_mask = [([1] * len(hypothesis)) + ([0] * pad_len) for hypothesis, pad_len in zip(hypothesis_input_ids, hypothesis_pad_len)]\n",
    "    hypothesis_input_ids = [hypothesis + [word2id['[PAD]']] * pad_len for hypothesis, pad_len in zip(hypothesis_input_ids, hypothesis_pad_len)]\n",
    "    #num_rows, max_seq_length\n",
    "    # Extract labels\n",
    "    labels = examples[\"label\"]\n",
    "    #num_rows\n",
    "    return {\n",
    "        \"premise_input_ids\": premise_input_ids,\n",
    "        \"premise_attention_mask\": premise_attn_mask,\n",
    "        \"hypothesis_input_ids\": hypothesis_input_ids,\n",
    "        \"hypothesis_attention_mask\": hypothesis_attn_mask,\n",
    "        \"labels\" : labels\n",
    "    }\n",
    "\n",
    "tokenized_datasets = raw_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['premise','hypothesis','label'])\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# initialize the dataloader\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets['train'], \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets['validation'], \n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets['test'], \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512])\n",
      "torch.Size([8, 512])\n",
      "torch.Size([8, 512])\n",
      "torch.Size([8, 512])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch['premise_input_ids'].shape)\n",
    "    print(batch['premise_attention_mask'].shape)\n",
    "    print(batch['hypothesis_input_ids'].shape)\n",
    "    print(batch['hypothesis_attention_mask'].shape)\n",
    "    print(batch['labels'].shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(bert);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = bert.BERT().to(device)\n",
    "model.load_state_dict(torch.load('./model/BERT3.pth'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "SBERT adds a pooling operation to the output of BERT / RoBERTa to derive a fixed sized sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mean pooling function\n",
    "def mean_pool(token_embeds, attention_mask):\n",
    "    # reshape attention_mask to cover 768-dimension embeddings\n",
    "    in_mask = attention_mask.unsqueeze(-1).expand(\n",
    "        token_embeds.size()\n",
    "    ).float()\n",
    "    # perform mean-pooling but exclude padding tokens (specified by in_mask)\n",
    "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(\n",
    "        in_mask.sum(1), min=1e-9\n",
    "    )\n",
    "    pool = pool.to(device)\n",
    "\n",
    "    return pool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loss Function\n",
    "\n",
    "## Classification Objective Function \n",
    "We concatenate the sentence embeddings $u$ and $v$ with the element-wise difference  $\\lvert u - v \\rvert $ and multiply the result with the trainable weight  $ W_t ∈  \\mathbb{R}^{3n \\times k}  $:\n",
    "\n",
    "$ o = \\text{softmax}\\left(W^T \\cdot \\left(u, v, \\lvert u - v \\rvert\\right)\\right) $\n",
    "\n",
    "where $n$ is the dimension of the sentence embeddings and k the number of labels. We optimize cross-entropy loss. This structure is depicted in Figure 1.\n",
    "\n",
    "## Regression Objective Function. \n",
    "The cosine similarity between the two sentence embeddings $u$ and $v$ is computed (Figure 2). We use means quared-error loss as the objective function.\n",
    "\n",
    "(Manhatten / Euclidean distance, semantically  similar sentences can be found.)\n",
    "\n",
    "<img src=\"./figures/sbert-architecture.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurations(u,v):\n",
    "    # build the |u-v| tensor\n",
    "    uv = torch.sub(u, v)   # batch_size,hidden_dim\n",
    "    uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
    "    \n",
    "    # concatenate u, v, |u-v|\n",
    "    x = torch.cat([u, v, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
    "    return x\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    dot_product = np.dot(u, v)\n",
    "    norm_u = np.linalg.norm(u)\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    similarity = dot_product / (norm_u * norm_v)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_head = torch.nn.Linear(768*3, 3).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "optimizer_classifier = torch.optim.Adam(classifier_head.parameters(), lr=2e-5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sung2_8l7o06c\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# and setup a warmup for the first ~10% steps\n",
    "total_steps = int(len(raw_dataset) / batch_size)\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "\t\toptimizer, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")\n",
    "\n",
    "# then during the training loop we update the scheduler per step\n",
    "scheduler.step()\n",
    "\n",
    "scheduler_classifier = get_linear_schedule_with_warmup(\n",
    "\t\toptimizer_classifier, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")\n",
    "\n",
    "# then during the training loop we update the scheduler per step\n",
    "scheduler_classifier.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = bert.max_len\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding(inputs_ids_a, segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def get_attn_pad_mask(seq_q, seq_k):\n",
    "# #     batch_size, len_q = seq_q.size()\n",
    "# #     batch_size, len_k = seq_k.size()\n",
    "# #     # eq(zero) is PAD token\n",
    "# #     pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "# #     pad_attn_mask.to(device)\n",
    "# #     return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k\n",
    "\n",
    "\n",
    "# enc_self_attn_mask = bert2.get_attn_pad_mask(inputs_ids_a, inputs_ids_a)\n",
    "# embedding = bert2.Embedding()\n",
    "# output = embedding(inputs_ids_a, segment_ids)\n",
    "\n",
    "# for i, layer in enumerate(test):\n",
    "#     print(i)\n",
    "#     output, _ = layer(output, enc_self_attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nn.ModuleList([bert.EncoderLayer() for _ in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderLayer(\n",
      "  (enc_self_attn): MultiHeadAttention(\n",
      "    (W_Q): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (W_K): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (W_V): Linear(in_features=768, out_features=512, bias=True)\n",
      "  )\n",
      "  (pos_ffn): PoswiseFeedForwardNet(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  )\n",
      ")\n",
      "EncoderLayer(\n",
      "  (enc_self_attn): MultiHeadAttention(\n",
      "    (W_Q): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (W_K): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (W_V): Linear(in_features=768, out_features=512, bias=True)\n",
      "  )\n",
      "  (pos_ffn): PoswiseFeedForwardNet(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  )\n",
      ")\n",
      "EncoderLayer(\n",
      "  (enc_self_attn): MultiHeadAttention(\n",
      "    (W_Q): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (W_K): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (W_V): Linear(in_features=768, out_features=512, bias=True)\n",
      "  )\n",
      "  (pos_ffn): PoswiseFeedForwardNet(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  )\n",
      ")\n",
      "EncoderLayer(\n",
      "  (enc_self_attn): MultiHeadAttention(\n",
      "    (W_Q): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (W_K): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (W_V): Linear(in_features=768, out_features=512, bias=True)\n",
      "  )\n",
      "  (pos_ffn): PoswiseFeedForwardNet(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  )\n",
      ")\n",
      "EncoderLayer(\n",
      "  (enc_self_attn): MultiHeadAttention(\n",
      "    (W_Q): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (W_K): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (W_V): Linear(in_features=768, out_features=512, bias=True)\n",
      "  )\n",
      "  (pos_ffn): PoswiseFeedForwardNet(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  )\n",
      ")\n",
      "EncoderLayer(\n",
      "  (enc_self_attn): MultiHeadAttention(\n",
      "    (W_Q): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (W_K): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (W_V): Linear(in_features=768, out_features=512, bias=True)\n",
      "  )\n",
      "  (pos_ffn): PoswiseFeedForwardNet(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for layer in test:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Embedding(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Embedding, self).__init__()\n",
    "#         self.tok_embed = nn.Embedding(17751, 768)  # token embedding\n",
    "#         self.pos_embed = nn.Embedding(max_len, 768)      # position embedding\n",
    "#         self.seg_embed = nn.Embedding(2, 768)  # segment(token type) embedding\n",
    "#         self.norm = nn.LayerNorm(768)\n",
    "\n",
    "#     def forward(self, x, seg):\n",
    "#         #x, seg: (bs, len)\n",
    "#         seq_len = x.size(1)\n",
    "#         pos = torch.arange(seq_len, dtype=torch.long)\n",
    "#         pos = pos.unsqueeze(0).expand_as(x)  # (len,) -> (bs, len)\n",
    "#         ### the error is in the next line\n",
    "\n",
    "#         # global x_fd, seg_fd, pos_fd\n",
    "#         # x_fd = x\n",
    "#         # seg_fd = seg\n",
    "#         # pos_fd = pos\n",
    "\n",
    "#         # print(x_fd.max(), pos_fd.max(), seg_fd.max())\n",
    "#         pos = pos.to(device)\n",
    "#         embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "#         out = self.norm(embedding)\n",
    "#         print(out.device)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [02:14<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | loss = 2.628225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [02:27<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | loss = 4.527915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [02:35<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | loss = 3.147285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [02:38<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | loss = 4.277563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [02:40<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | loss = 2.206258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "num_epoch = 5\n",
    "# 1 epoch should be enough, increase if wanted\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()  \n",
    "    classifier_head.train()\n",
    "    # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
    "    torch.set_default_device('cpu')\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, leave=True)):\n",
    "        # zero all gradients on each new step\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_classifier.zero_grad()\n",
    "        \n",
    "        # prepare batches and more all to the active device\n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        label = batch['labels'].to(device)\n",
    "        \n",
    "        # # extract token embeddings from BERT at last_hidden_state\n",
    "        # u = model(inputs_ids_a, attention_mask=attention_a)  \n",
    "        # v = model(inputs_ids_b, attention_mask=attention_b)  \n",
    "\n",
    "        segment_ids = torch.zeros(batch_size, max_len, dtype=torch.int32).to(device)\n",
    "\n",
    "        u_last_hidden_state = model.last_hidden_state(inputs_ids_a, segment_ids) # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "        v_last_hidden_state = model.last_hidden_state(inputs_ids_b, segment_ids) # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "         # get the mean pooled vectors\n",
    "        u_mean_pool = mean_pool(u_last_hidden_state, attention_a) # batch_size, hidden_dim\n",
    "        v_mean_pool = mean_pool(v_last_hidden_state, attention_b) # batch_size, hidden_dim\n",
    "        \n",
    "        # build the |u-v| tensor\n",
    "        uv = torch.sub(u_mean_pool, v_mean_pool)   # batch_size,hidden_dim\n",
    "        uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
    "        \n",
    "        # concatenate u, v, |u-v|\n",
    "        x = torch.cat([u_mean_pool, v_mean_pool, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
    "        \n",
    "        # process concatenated tensor through classifier_head\n",
    "        x = classifier_head(x) #batch_size, classifer\n",
    "        \n",
    "        # calculate the 'softmax-loss' between predicted and true label\n",
    "        loss = criterion(x, label)\n",
    "        \n",
    "        # using loss, calculate gradients and then optimizerize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_classifier.step()\n",
    "\n",
    "        scheduler.step() # update learning rate scheduler\n",
    "        scheduler_classifier.step()\n",
    "        torch.set_default_device('cpu')\n",
    "        \n",
    "    print(f'Epoch: {epoch + 1} | loss = {loss.item():.6f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity: 0.9960\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "classifier_head.eval()\n",
    "total_similarity = 0\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        # prepare batches and more all to the active device\n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        label = batch['labels'].to(device)\n",
    "        \n",
    "        # extract token embeddings from BERT at last_hidden_state\n",
    "        segment_ids = torch.zeros(batch_size, max_len, dtype=torch.int32).to(device)\n",
    "\n",
    "        u = model.last_hidden_state(inputs_ids_a, segment_ids) # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "        v = model.last_hidden_state(inputs_ids_b, segment_ids) # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "        # get the mean pooled vectors\n",
    "        u_mean_pool = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1) # batch_size, hidden_dim\n",
    "        v_mean_pool = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1) # batch_size, hidden_dim\n",
    "\n",
    "        similarity_score = cosine_similarity(u_mean_pool, v_mean_pool)\n",
    "        total_similarity += similarity_score\n",
    "    \n",
    "average_similarity = total_similarity / len(eval_dataloader)\n",
    "print(f\"Average Cosine Similarity: {average_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './model/SBERT.pt')\n",
    "torch.save(model.state_dict(), './model/SBERT.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(bert);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = bert.BERT().to(device)\n",
    "model.load_state_dict(torch.load('./model/SBERT.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "\n",
    "tokenizer = spacy.load(\"en_core_web_sm\")\n",
    "word2id = pickle.load(open('./model/elements/word2id.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(sent):\n",
    "    max_seq_length = 512\n",
    "    tokens = tokenizer(re.sub(\"[.,!?\\\\-']=\", ' ', sent.lower()))\n",
    "    input_ids = [word2id['[CLS]']] + [word2id[str(token)] for token in tokens if str(token) in word2id] + [word2id['[SEP]']]\n",
    "    pad_len = max_seq_length - len(input_ids)\n",
    "    attn_mask = ([1] * len(input_ids)) + ([0] * pad_len)\n",
    "    input_ids += [word2id['[PAD]']] * pad_len\n",
    "\n",
    "    input_ids_tensor = torch.tensor(input_ids).unsqueeze(0).to(device)\n",
    "    attn_mask_tensor = torch.tensor(attn_mask).unsqueeze(0).to(device)\n",
    "\n",
    "    return input_ids_tensor, attn_mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 512)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9988\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(model, sentence_a, sentence_b, device):\n",
    "    # Tokenize and convert sentences to input IDs and attention masks\n",
    "    inputs_ids_a, attention_a = my_tokenizer(sentence_a)\n",
    "    inputs_ids_b, attention_b = my_tokenizer(sentence_b)\n",
    "\n",
    "    # Extract token embeddings from BERT\n",
    "    segment_ids = torch.zeros(batch_size, max_len, dtype=torch.int32).to(device)\n",
    "\n",
    "    u = model.last_hidden_state(inputs_ids_a, segment_ids) # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "    v = model.last_hidden_state(inputs_ids_b, segment_ids) # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "    # Get the mean-pooled vectors\n",
    "    u = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
    "    v = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity_score = cosine_similarity(u.reshape(1, -1), v.reshape(1, -1))[0, 0]\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "# Example usage:\n",
    "sentence_a = 'Your contribution helped make it possible for us to provide our students with a quality education.'\n",
    "sentence_b = \"Your contributions were of no help with our students' education.\"\n",
    "similarity = calculate_similarity(model, sentence_a, sentence_b, device)\n",
    "print(f\"Cosine Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modules.json: 100%|██████████| 349/349 [00:00<?, ?B/s] \n",
      "c:\\Users\\sung2_8l7o06c\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sung2_8l7o06c\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 136kB/s]\n",
      "README.md: 100%|██████████| 10.7k/10.7k [00:00<00:00, 10.7MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<?, ?B/s]\n",
      "config.json: 100%|██████████| 612/612 [00:00<?, ?B/s] \n",
      "pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:13<00:00, 6.75MB/s]\n",
      "c:\\Users\\sung2_8l7o06c\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "tokenizer_config.json: 100%|██████████| 350/350 [00:00<?, ?B/s] \n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 5.63MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 548kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<?, ?B/s] \n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<?, ?B/s] \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "pretrained_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.5605\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity2(model, sentence_a, sentence_b):\n",
    "    encoded_a = model.encode(sentence_a)\n",
    "    encoded_b = model.encode(sentence_b)\n",
    "    return cosine_similarity(encoded_a.reshape(1, -1), encoded_b.reshape(1, -1))[0, 0]\n",
    "\n",
    "# Example usage:\n",
    "sentence_a = 'Your contribution helped make it possible for us to provide our students with a quality education.'\n",
    "sentence_b = \"Your contributions were of no help with our students' education.\"\n",
    "similarity = calculate_similarity2(pretrained_model, sentence_a, sentence_b)\n",
    "print(f\"Cosine Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: \twell they're dangerous\n",
      "Hypothesis: \tThey offer nothing to worry about.\n",
      "\tLabel: \t\t2  (contradition; expected 0)\n",
      "\tMy sim: \t0.9972643852233887\n",
      "\tPt sim: \t0.24803051352500916\n",
      "\n",
      "\n",
      "\n",
      "Premise: \tA man wearing snow gear hiking.\n",
      "Hypothesis: \tA man hikes in winter.\n",
      "\tLabel: \t\t0  (entailment; expected 1)\n",
      "\tMy sim: \t0.9988747239112854\n",
      "\tPt sim: \t0.8531558513641357\n",
      "\n",
      "\n",
      "\n",
      "Premise: \tA man in a blue shirt, jeans, and wearing a tool belt is climbing down a metal rod.\n",
      "Hypothesis: \tA person is flying an airplane.\n",
      "\tLabel: \t\t2  (contradition; expected 0)\n",
      "\tMy sim: \t0.9990731477737427\n",
      "\tPt sim: \t0.043636757880449295\n",
      "\n",
      "\n",
      "\n",
      "Premise: \tA baby wearing a \"my best buddy\" shirt on a bed.\n",
      "Hypothesis: \tTHe baby is sitting in the highchair.\n",
      "\tLabel: \t\t2  (contradition; expected 0)\n",
      "\tMy sim: \t0.997869610786438\n",
      "\tPt sim: \t0.40219008922576904\n",
      "\n",
      "\n",
      "\n",
      "Premise: \tTours originate from the center.\n",
      "Hypothesis: \tTours start in the plaza downtown.\n",
      "\tLabel: \t\t1  (neutral; expected 0.5)\n",
      "\tMy sim: \t0.9990047216415405\n",
      "\tPt sim: \t0.6614198684692383\n",
      "\n",
      "\n",
      "\n",
      "Premise: \tTwo friends talk at a bar.\n",
      "Hypothesis: \tTwo friends are talking to eachother.\n",
      "\tLabel: \t\t0  (entailment; expected 1)\n",
      "\tMy sim: \t0.993681788444519\n",
      "\tPt sim: \t0.7636969089508057\n",
      "\n",
      "\n",
      "\n",
      "Premise: \tbut uh seems like it's just dull and uninspiring here\n",
      "Hypothesis: \tBeing around here has been beyond thrilling. \n",
      "\tLabel: \t\t2  (contradition; expected 0)\n",
      "\tMy sim: \t0.998803973197937\n",
      "\tPt sim: \t0.3734223246574402\n",
      "\n",
      "\n",
      "\n",
      "Premise: \tTwo men in white shirts with suspenders, blue neckties, and gray hats, stand to the side as people walk by.\n",
      "Hypothesis: \tTwo men wearing shirts, ties, and hats stand as people walk past.\n",
      "\tLabel: \t\t0  (entailment; expected 1)\n",
      "\tMy sim: \t0.998677134513855\n",
      "\tPt sim: \t0.8041025400161743\n",
      "\n",
      "\n",
      "\n",
      "Premise: \tIn that analysis FDA discusses the need for the rule, the benefits anticipated from the implementation of the rule, and a summary of the impacts of the final rule.\n",
      "Hypothesis: \tThe rule may be unpopular among drug manufacturers but the benefits outweigh those concerns.\n",
      "\tLabel: \t\t1  (neutral; expected 0.5)\n",
      "\tMy sim: \t0.9989148378372192\n",
      "\tPt sim: \t0.4790887236595154\n",
      "\n",
      "\n",
      "\n",
      "Premise: \tA man is sleeping on a subway seat.\n",
      "Hypothesis: \tPeople are eating their lunch on the subway.\n",
      "\tLabel: \t\t2  (contradition; expected 0)\n",
      "\tMy sim: \t0.9975006580352783\n",
      "\tPt sim: \t0.43046462535858154\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    p, h, l = ['premise', 'hypothesis', 'label']\n",
    "    p = raw_dataset['train'][p][i]\n",
    "    h = raw_dataset['train'][h][i]\n",
    "    l = raw_dataset['train'][l][i]\n",
    "    l = f\"{l}  ({['entailment; expected 1', 'neutral; expected 0.5', 'contradition; expected 0'][l]})\"\n",
    "    my_similarity = calculate_similarity(model, p, h, device)\n",
    "    pt_similarity = calculate_similarity2(pretrained_model, p, h)\n",
    "    print(f'Premise: \\t{p}')\n",
    "    print(f'Hypothesis: \\t{h}')\n",
    "    print(f'\\tLabel: \\t\\t{l}')\n",
    "    print(f'\\tMy sim: \\t{my_similarity}')\n",
    "    print(f'\\tPt sim: \\t{pt_similarity}')\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_label(example):\n",
    "    label_map = {0: 1,  # entailment sentences (label == 0) should have a cosine similarity of 1\n",
    "                 1: 0,  # neutral sentences (label == 1) should have a cosine similarity of 0\n",
    "                 2: -1  # contradiction sentences (label == 2) should have a cosine similarity of -1\n",
    "                }\n",
    "    \n",
    "    example['label'] = label_map[example['label']]\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation between my_similarity and l_cossim: 0.0079\n",
      "Spearman correlation between pt_similarity and l_cossim: 0.1344\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "result = []\n",
    "\n",
    "my_similarities = []\n",
    "pt_similarities = []\n",
    "l_cossims = []\n",
    "\n",
    "for sample in raw_dataset['test']:\n",
    "    p, h, l = ['premise', 'hypothesis', 'label']\n",
    "    p = sample[p]\n",
    "    h = sample[h]\n",
    "    l = sample[l]\n",
    "    l_cossim = [1, 0.5, 0][l]\n",
    "\n",
    "    my_similarity = calculate_similarity(model, p, h, device)\n",
    "    pt_similarity = calculate_similarity2(pretrained_model, p, h)\n",
    "\n",
    "    my_similarities.append(my_similarity)\n",
    "    pt_similarities.append(pt_similarity)\n",
    "    l_cossims.append(l_cossim)\n",
    "\n",
    "correlation_my = spearmanr(my_similarities, l_cossims)[0]\n",
    "correlation_pt = spearmanr(pt_similarities, l_cossims)[0]\n",
    "\n",
    "print(f\"Spearman correlation between my_similarity and l_cossim: {correlation_my:.4f}\")\n",
    "print(f\"Spearman correlation between pt_similarity and l_cossim: {correlation_pt:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
